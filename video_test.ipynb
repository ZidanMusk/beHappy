{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GT 740M (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from numpy import genfromtxt\n",
    "from lasagne.layers import batch_norm ,dropout,DenseLayer\n",
    "\n",
    "conv = lasagne.layers.Conv2DLayer\n",
    "pool = lasagne.layers.MaxPool2DLayer\n",
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "DIM = 48\n",
    "DATA_SIZE = 35887\n",
    "NUM_CLASSES = 10\n",
    "FILE_NAME = \"fer2013/fer2013.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters in model: 2388970\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_width, input_height, output_dim):\n",
    "    ini = lasagne.init.HeUniform(gain='relu')\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, input_width, input_height),)\n",
    "    \n",
    "    class_l1 = batch_norm(conv(\n",
    "        l_in,\n",
    "        num_filters=32,pad='same',\n",
    "        filter_size=(3, 3),\n",
    "        #filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    ))\n",
    "    class_d0 = dropout(class_l1,p=0.3)\n",
    "    \n",
    "    class_l2 = batch_norm(conv(\n",
    "        class_d0,\n",
    "        num_filters=32,pad='same',\n",
    "        filter_size=(3, 3),\n",
    "        #filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    ))\n",
    "    class_d1 = dropout(class_l2,p=0.3)\n",
    "    \n",
    "    \n",
    "    class_l3 = batch_norm(conv(\n",
    "        class_d1,\n",
    "        num_filters=32,pad='same',\n",
    "        filter_size=(3, 3),\n",
    "        #filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    ))\n",
    "    class_d2 = dropout(class_l3,p=0.35)\n",
    "    \n",
    "    \n",
    "    class_l4 = batch_norm(conv(\n",
    "        class_d2,\n",
    "        num_filters=32,pad='same',\n",
    "        filter_size=(3, 3),\n",
    "        #filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    ))\n",
    "    class_d3 = dropout(class_l4,p=0.2)   \n",
    "    #class_l5 = pool(class_l4, pool_size=(2, 2))\n",
    "    \n",
    "    \n",
    "    class_l1_dens = batch_norm(DenseLayer(\n",
    "        class_d3,\n",
    "        num_units=32,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    )) \n",
    "    class_d1_dens = dropout(class_l1_dens,0.3)\n",
    "    \n",
    "    class_l2_dens = batch_norm(DenseLayer(\n",
    "        class_d1_dens,\n",
    "        num_units=32,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    )) \n",
    "    class_d2_dens = dropout(class_l2_dens,p=0.2)\n",
    "    \n",
    "    l_out = DenseLayer(\n",
    "        class_d2_dens,\n",
    "        num_units=output_dim,\n",
    "        nonlinearity=lasagne.nonlinearities.softmax,\n",
    "        W=ini,\n",
    "    )\n",
    "    return l_out\n",
    "\n",
    "model= build_model(DIM, DIM, NUM_CLASSES)\n",
    "print(\"number of parameters in model: %d\" % lasagne.layers.count_params(model, trainable=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setting up the graph in theano\n",
    "sym_x = T.tensor4('sym_x') # a symbolic variable, this is now a 4-D tensor.\n",
    "sym_t = T.ivector('sym_t') # a symbolic variable taking on the value of the target batch.\n",
    "\n",
    "# Retrieve network output\n",
    "train_out = lasagne.layers.get_output(model, sym_x, deterministic=False)\n",
    "eval_out = lasagne.layers.get_output(model, sym_x, deterministic=True)\n",
    "\n",
    "# Retrieve list of all trainable parameters in the network.\n",
    "all_params = lasagne.layers.get_all_params(model, trainable=True)\n",
    "\n",
    "# add weight decay\n",
    "all_layers = lasagne.layers.get_all_layers(model)\n",
    "l2_penalty = lasagne.regularization.regularize_layer_params(all_layers, lasagne.regularization.l2) * 0.001\n",
    "\n",
    "\n",
    "#reg2 = lasagne.regularization.l2(train_out)\n",
    "#reg = lasagne.regularization.l1( train_out )\n",
    "cost = lasagne.objectives.categorical_crossentropy(train_out+1e-8, sym_t).mean()\n",
    "\n",
    "# Let Theano do its magic and get all the gradients we need for training\n",
    "all_grads = T.grad(cost, all_params)\n",
    " \n",
    "# Set the update function for parameters \n",
    "# you might wan't to experiment with more advanded update schemes like rmsprob, adadelta etc.\n",
    "sh_lr = theano.shared(lasagne.utils.floatX(LEARNING_RATE))\n",
    "\n",
    "Updates = lasagne.updates.adam(all_grads, all_params, learning_rate=sh_lr)\n",
    "\n",
    "f_eval = theano.function([sym_x],eval_out, on_unused_input='warn')\n",
    "\n",
    "f_train = theano.function([sym_x, sym_t],[cost],updates=Updates, on_unused_input='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with np.load('weights.npz') as f:\n",
    "    param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "lasagne.layers.set_all_param_values( model, param_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "# (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "fig = plt.figure()\n",
    "cv2.destroyAllWindows()\n",
    "cap = cv2.VideoCapture(0)\n",
    "ii= 0\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ii == 10:\n",
    "        ii=0\n",
    "    else:\n",
    "        ii +=1\n",
    "        continue\n",
    "    #start here\n",
    "    img = frame\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    facelocs = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    faces = np.ndarray(shape=(1, 48*48), dtype=np.uint8)\n",
    "    for (x,y,w,h) in facelocs:\n",
    "        face = gray[y:y + h, x: x + w]\n",
    "        face = cv2.resize(face, (48, 48), interpolation = cv2.INTER_CUBIC)\n",
    "        face = np.array(face)\n",
    "        face = np.reshape(face, 48*48)\n",
    "        faces = np.vstack((faces, face))\n",
    "    faces = np.delete(faces, 0, 0)\n",
    "    if faces.shape[0]!=0: \n",
    "        modes = np.array(['emojis/happy.png','emojis/disgust.png','emojis/fear.png','emojis/happy.png',\n",
    "                      'emojis/sad.png','emojis/surprised.png','emojis/neutral.png'])\n",
    "        faces = faces.reshape((faces.shape[0], 1, DIM, DIM))\n",
    "        #print faces.shape\n",
    "        net_out = f_eval(faces)   \n",
    "        preds = np.argmax(net_out, axis=-1)\n",
    "        i = 0\n",
    "        for (x, y, w, h) in facelocs:\n",
    "            emoji_r = cv2.cvtColor(cv2.imread(modes[preds[i]], -1), cv2.COLOR_BGRA2RGBA)\n",
    "            emoji = cv2.resize(emoji_r, (w, h), interpolation = cv2.INTER_CUBIC)\n",
    "            i+=1\n",
    "            for c in range(0,3):\n",
    "                img[y:y + h, x:x+w, c] = emoji[:,:,c] * (emoji[:,:,3]/255.0) + img[y:y+h, x:x+w, c] * (1.0 - emoji[:,:,3]/255.0)\n",
    "    \n",
    "    cv2.imshow('frame',img)\n",
    "    #end here\n",
    "    \n",
    "    # Our operations on the frame come here\n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    #cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
